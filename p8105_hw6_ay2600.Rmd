---
title: "Data Science I HW 6"
author: "Hingling Yu"
date: "2023-11-29"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)
library(rnoaa)
library(dplyr)
library(modelr)
library(purrr)
library(skimr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```


## Problem 2
### Fetching and preparing weather data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())

```

### Create bootstrap function 

```{r}
set.seed(2)
sample_bootstrap = 
  function(data_frame) {
    data_frame %>% sample_frac(replace = TRUE)
  }

```

### Create 5000 bootstrap samples

```{r}
bootstrap_data = 
  weather_df %>%  
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    lm_models = map(strap, ~lm(tmax ~ tmin + prcp, data = .)),
    beta_glance = map(lm_models, broom::glance),
    beta_tidy = map(lm_models, broom::tidy)) %>% 
  unnest(beta_glance, beta_tidy) %>% 
  select(.id, term, estimate, r.squared) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate
  ) %>% 
  rename(
    beta_0 = `(Intercept)`,
    beta_1 = tmin,
    beta_2 = prcp
  )
```

### Confidence interval for $\hat{r}^2$

```{r}
r_squared_ci = 
  bootstrap_data %>%
  select(r.squared) %>%
  summarize(
    ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared, 0.975)
  )

r_squared_ci
```
### Plotting distribution of $\hat{r}^2$
```{r}
bootstrap_data %>%
  select(r.squared) %>%
  ggplot(aes(x = r.squared)) + 
  geom_density(fill = "pink", color = "black") + 
  labs(
    title = "Density of R-Squared Bootstrap Estimates",
    x = "R-squared Estimate",
    y = "Density"
  )
```
### Plot Description $\hat{r}^2$

- The distribution appears to be skewed left, indicating that most of the bootstrap samples resulted in \(R^2\) values closer to the higher end of the scale, with fewer samples showing lower \(R^2\). The peak of the density is around 0.92, suggesting that the linear model explains a substantial portion of the variance in the maximum temperature based on the minimum temperature, on most occasions.


### Confidence interval for $\log(\hat{\beta}_0 \ast \hat{\beta}_1)$

```{r}
bootstrap_log_values = 
  bootstrap_data %>% 
  mutate(
    log_beta_product = log(beta_0 * beta_1)
  )

# Confidence interval log_beta
log_beta_ci = 
  bootstrap_log_values %>%
  select(log_beta_product) %>% 
  summarize(
    ci_lower = quantile(log_beta_product, 0.025),
    ci_upper = quantile(log_beta_product, 0.975)
  )

log_beta_ci
```

### Plot distribution for $\log(\hat{\beta}_1 \ast \hat{\beta}_2)$
```{r}
bootstrap_log_values %>%
  select(log_beta_product) %>%
  ggplot(aes(x = log_beta_product)) + 
  geom_density(fill = "lightblue", color = "black") + 
  labs(
    title = "Density of Log Beta Product Bootstrap Estimates",
    x = "Log Product Estimate",
    y = "Density"
  )
```

### Plot Description

- This plot displays the density of the logarithm of the product of two regression coefficients,\(\beta_{tmin}\) and \(\beta_{prcp}\). This distribution seems fairly symmetrical and bell-shaped, centering around 2.10, indicating that the log-transformed product of the coefficients varies less and is more consistent across bootstrap samples compared to the \(R^2\) values.

## Problem 3

### Load/tidy the `birthweight.csv` and convert factors

```{r}
birthweight_data =
  read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present"))
  )

# Check for missing datas

skimr::skim(birthweight_data)
```

- According to the `skim()` summary statistics, there's no missing data.


### Regression Models for `birthweight_data`
```{r}
model1 <- lm(bwt ~ gaweeks + ppbmi + momage + smoken + wtgain, data = birthweight_data)
summary(model1)
```


### Predictions and residuals
```{r}
# Add predictions and residuals to the dataset
birthweight_data_pr = 
  birthweight_data %>%
  add_predictions(model1, var = "predicted") %>%
  add_residuals(model1, var = "residuals")

# ggplot
birthweight_data_pr %>% 
  ggplot(aes(x = predicted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values (Predicted Birth Weight)",
    y = "Residuals (Observed - Predicted)"
  )

```

- In our analysis, we developed a linear regression model to predict birthweight, focusing on key variables like gestational age, mother’s pre-pregnancy BMI, mother’s age, smoking during pregnancy, and weight gain during pregnancy. These predictors were selected based on a hypothesized structure using known medical insights. 



### Comparation using cross-validated prediction error
```{r}
# Cross-validate
cv_df <- crossv_mc(birthweight_data, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

# Fit models
cv_df <- cv_df %>% 
  mutate(
    my_model = map(train, ~lm(bwt ~ gaweeks + ppbmi + momage + smoken + wtgain, data = .x)),
    model2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model3 = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))) %>% 
  mutate(
    rmse_my_model = map2_dbl(my_model, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y)))

# Plot
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + 
  geom_violin() +
  scale_fill_brewer(palette = "Pastel1")

```

- From the plot, the model 3 can best predict the birthweight sicne it has the lowest RMSE value.







